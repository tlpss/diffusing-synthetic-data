{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsd import DATA_DIR\n",
    "from dsd.diffusion_rendering import *\n",
    "from dsd.cropped_diffusion_rendering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = DATA_DIR / \"renders/mugs/100/Threshold_porcelain_Coffee_Mug_All_over_bead/018\"\n",
    "input_images = DiffusionRenderInputImages.from_render_dir(image_dir)\n",
    "#input_images.depth_image[input_images.depth_image > 1.0] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_results(images):\n",
    "    # plot original image and depth, as well as the processed images\n",
    "    fig, axes = plt.subplots(4,4, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for i, image in enumerate(images):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(np.array(image))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength = 1.0\n",
    "controlnet_conditioning_scale = 1.3\n",
    "n_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = SD15RealisticCheckpointControlNetFromDepthRenderer(num_inference_steps=n_steps,controlnet_conditioning_scale=controlnet_conditioning_scale,strength=strength)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_renderer = CroppedRenderer(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inpainter = SD2NormalCheckpointInpaintRenderer(num_images_per_prompt=4, num_inference_steps=n_steps, strength = 1.0)\n",
    "inpainter = SD2InpaintingRenderer(num_images_per_prompt=4, num_inference_steps=n_steps, strength = 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_and_inpaint_renderer = CropAndInpaintRenderer(cropped_renderer, inpainter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a white, ceramic mug with a picture of a dog, natural light, RAW\"\n",
    "background_prompt = \"a table in a messy robot lab, natural light, RAW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s2_images = crop_and_inpaint_renderer(prompt, background_prompt, input_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1_results = cropped_renderer(prompt, input_images)\n",
    "stage_2_inputs = DiffusionRenderInputImages(np.copy(input_images.rgb_image), np.copy(input_images.depth_image), np.copy(input_images.mask))\n",
    "# dilate the mask to inpaint the background\n",
    "original_mask = np.copy(stage_2_inputs.mask)\n",
    "stage_2_inputs.mask = cv2.dilate(stage_2_inputs.mask, np.ones((5,5), np.uint8), iterations=1)\n",
    "# invert the mask to inpaint the background\n",
    "stage_2_inputs.mask = 1 - stage_2_inputs.mask\n",
    "# duplicate the input image to create one for each stage 1 result\n",
    "stage_2_inputs = [copy.deepcopy(stage_2_inputs) for _ in stage_1_results]\n",
    "# set the input images to the stage 1 results\n",
    "stage_2_results = []\n",
    "for i, result in enumerate(stage_1_results):\n",
    "    stage_2_inputs[i].rgb_image = np.array(result).astype(np.float32)/255.0\n",
    "    stage_2_result = inpainter(background_prompt, stage_2_inputs[i])\n",
    "    for j, image in enumerate(stage_2_result):\n",
    "        image = np.array(image).astype(np.float32)/255.0\n",
    "        image[original_mask > 0.5] = stage_2_inputs[i].rgb_image[original_mask >  0.5]\n",
    "        stage_2_result[j] = Image.fromarray((image*255).astype(np.uint8))\n",
    "    stage_2_results.extend(stage_2_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_results(stage_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
